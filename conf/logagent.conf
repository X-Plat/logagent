##########
# COMLOG #
##########
# 进程名
# [默认配置(字符串),  COMLOG_PROCNAME : test]
COMLOG_PROCNAME : bigpipe_logagent
# 设备数目
# [默认配置(uint),  COMLOG_DEVICE_NUM : 2]
COMLOG_DEVICE_NUM : 1 
# 设备0 名
# [默认配置(字符串),  COMLOG_DEVICE0 : FILE]
COMLOG_DEVICE0 : FILE
# 日志等级
# [默认配置(uint),  COMLOG_LEVEL : 16]
COMLOG_LEVEL : 16
# 设备类型, ULLOG
# [默认配置(字符串),  FILE_TYPE : ULLOG]
FILE_TYPE : ULLOG
# 日志名
# [默认配置(字符串),  FILE_NAME : test.log]
FILE_NAME : bigpipe_logagent.log
# 日志路径
# [默认配置(字符串),  FILE_PATH : ./log]
FILE_PATH : ./log
# 是否打开这个设备
# [默认配置(uint),  FILE_OPEN : 1]
FILE_OPEN : 1

#######
# BMQ #
#######
# 各种超时。对应于read command(BMQ_CONNECTED/BMQ_ACK/BMQ_RECEIPT/BMQ_MESSAGE/...)
bmq_read_timeo: 5000
bmq_write_timeo: 5000
bmq_conn_timeo: 5000

# 重试次数。通信失败时，会自动重新连接到同一ip/port，直到超过这个次数，这可以解决网络瞬断问题。但是当前版本的Bigpipe屏蔽了这个功能
bmq_retry_cnt: 3

# failover类型
#   0 = 不尝试
#   1 = 从zookeeper中获得ip/port，直到超过bmq_failover_cnt指定的次数
bmq_failover_type: 1

# failover次数
bmq_failover_cnt: 20

# 仅针对发布者：异步发送窗口
bmq_send_window_size: 50

# 仅针对订阅者：连接倾向
#   0 = 从所有broker中任选
#   1 = 仅连接到primary，适用于对实时性高的需求
#   2 = 从secondary中任选，适用于大吞吐的需求
bmq_connection_preference: 0

# 数据持久化路径，.tpmeta、.subinfo、.progress文件将保存在这里
bmq_persist_path: ./persist_path

# 调试专用：允许持久化订阅信息
bmq_auto_persist_sub_info: 1
# 调试专用：允许持久化发布信息（meta信息如topic的位置）
bmq_auto_persist_tpmeta: 1

###########
# BIGPIPE #
###########
# 允许发送/校验checksum
need_checksum: 1

checksum_level : 2

# 仅针对发布者：允许自动存储进度
need_progress: 1

# 仅针对发布者：进度存储时间间隔，单位：毫秒
progress_save_interval: 1000

# 仅针对发布者：进度存储数量间隔，每发布指定数量的日志时，存储进度
progress_save_counter:  10

# 仅针对发布者：打包（batch）发布时间间隔，单位：毫秒，负数或零表示永远不会自动打包，除非到达batch_flush_counter或者手工flush
batch_flush_interval: 0

# 仅针对发布者：打包（batch）发布数量间隔，每发布指定数量的日志时，打包发送
batch_flush_counter: 40

# 仅针对发布者：发布限速，单位：字节/秒，负数、零、0x7FFFFFFFFFFFFFFF都表示不限速
publisher_speed_threshold : 0

# 仅针对订阅者：订阅限速，单位：字节/秒，负数、零、0x7FFFFFFFFFFFFFFF都表示不限速
subscriber_speed_threshold: 0

####################
# bigpipe meta配置 #
####################
# meta cache大小
max_cache_count: 100000

# zkc的watcher的超时时间，需大于zk配置的session timeout。单位：毫秒
watcher_timeout: 10000

# 读者观察到数据开始修改后，超过这个时间可以cache，最好大于watcher_timeout。单位：毫秒
setting_timeout: 15000

# zookeeper value的最大长度
max_value_size: 10240000

# zookeeper日志文件
zk_log_file: ./log/zookeeper.log

# zookeeper日志级别
zk_log_level: 3
# meta服务器的位置
meta_host : cq01-bigpipe-zk001.cq01:2181,cq01-bigpipe-zk002.cq01:2181,yf-bigpipe-zk003.yf01:2181,yf-bigpipe-zk004.yf01:2181,m1-bigpipe-zk005.m1:2181

# meta数据的根目录
root_path : /bigpipe_spider_cluster

############
# LOGAGENT #
############
# 数据源路径
datasource : /home/work/test 

# pipe名字
pipename : pipename

# token
token : token

# 当打开新文件时是否发送文件切分标记
open_eof_packet: 1
#碰到eof的时候是否发送
eof_send_to_all : 1

# 当没有内容更新时是否发送心跳标记，如果没有特殊需要就不要打开
open_heartbeat_packet: 0

#  设置心跳时间间隔 单位毫秒 如果不设置默认发送间隔为5s
# hb_interval : 5000

# 是否跳过长于2M的日志. 1为跳过，0为不跳过
# skip_long_line : 1
# 是否开启日志格式化
# open_log_format: 1

#日志格式化so路径
# format_lib_path : ./lib/liblogformat_api.so

# 格式化日志文件模块的配置文件名，如果没有此项，默认为: 'logformat.conf'
# format_conf_filename : logformat.conf

#提取时间字符串长度
#time_str_len : 100

# 读到EOF后等待的时间，单位：毫秒。如果数据源的产生速度较慢，可以设置为2000以便降低文件扫描的开销。如果对实时性要求较高，可以设置为100
sleep_time: 2000

# 对消息进行切分的动态库
partition_lib_path : ./lib/libhash_partitioner.so

# 动态库中对消息进行切分的函数名
partition_func_name: hostname_partition

#动态库的tag标签
tag_func_name : hostname_customize_tag

#定制tag，用于区分同一个hostname下的不同模块
customize_string : moduleA

#在hostname partion中从配置文件中读取hostnmae
conf_hostname : dxsearch.baidu.com

#是否打开字段提取（bws）
get_field : 0 
#字段提取函数，动态库
extract_func_name : extract_bwstime

#匹配字段提取的正则表达式
field_match_str : \[\d{2}/[A-Za-z]{3}/\d{4}[:\d{2}]{3}.+\+\d{4}\]

# 首次启动开始发布的文件路径。如果存在进度文件，则使用进度文件中的文件路径，忽略本设置。如果指定的文件不存在，则从第1个文件开始发送
start_file_name : /home/work/log/access_log.00

# 文件名前缀。只有以该字符串开始的文件才会发布；留空表示不限制
file_name_prefix : test.log
